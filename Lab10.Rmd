---
title: "NotTeamOnelab10"
author: "David Orozco, Ethan Schacht, Anderson Mun, Arie del Valle, Ryan Tate"
date: "March 20, 2019"
output: html_document
---

```{r,echo=FALSE, include=FALSE}
library(tidyverse)
library(lubridate)
library(stringr)
library(data.table)

Questions <- read.csv("Questions_trunc.csv")
Answers <- read.csv("answers_trunc.csv")

# merged <- left_join(Questions, Answers, by = c("Id" = "ParentId")) as NAs in date set

merged <- inner_join(Questions, Answers, by = c("Id" = "ParentId"))

```
```{r,echo=FALSE}
merged2 <- merged %>%
  mutate(question_title = Title, question_date = CreationDate.x, answer_date = CreationDate.y,
         question_score = Score.x, answer_score = Score.y,
         question_body = Body.x, answer_body = Body.y,
         question_id = Id, question_asker_id = OwnerUserId.x, question_answerer_id = OwnerUserId.y) %>%
  select(-CreationDate.x, -CreationDate.y, -Score.x, -Score.y, -Body.x, -Body.y, -Id, -X.x, -X.y, -Id.y, -OwnerUserId.x, -OwnerUserId.y, -Title)

merged3 <- merged2[c(8,9,1:2,4,6,10,3,5,7)]

merged3$question_date <- ymd_hms(merged3$question_date)
merged3$answer_date <- ymd_hms(merged3$answer_date)
```
****
####Team Section
****

* Question: What is the relationship between the timeliness of an answer and its score?


```{r,echo = FALSE}
dat <- merged3 %>% separate("question_date", into = c("date1","time1"), sep = " ") %>% separate("answer_date", into = c("date2","time2"), sep = " ") 
dat$date1 <- 

diff <- merged3 %>% mutate(diff = answer_date - question_date)
diff <- diff %>% mutate(relative = as.duration(diff)) %>% filter(diff > 0 )
dif <- diff %>% filter(diff < 1000)
#dif <- diff[,c(1:5,8,9,11,12)]%>% arrange(desc(question_id))
#loop <- unique(diff)

yote <- diff %>% mutate(sec = str_detect(relative, "s$"),min = str_detect(relative, "minute"),hour = str_detect(relative, "hour"), week = str_detect(relative, "week"),days = str_detect(relative, "day"), year = str_detect(relative, "year")) %>% arrange(-desc(diff))

s <- yote[c(1:45),]

m <- yote %>% filter(min == "TRUE") %>% mutate(min = diff/60) %>% arrange(desc(diff))
h <- yote %>% filter(hour == "TRUE")  %>% mutate(hour = diff/3600) %>% arrange(desc(diff))
d <- yote %>% filter(days == "TRUE")  %>% mutate(day = diff/(3600*24)) %>% arrange(desc(diff))
w <- yote %>% filter(week == "TRUE")  %>% mutate(week = diff/(3600*24*7)) %>% arrange(desc(diff))
y <- yote %>% filter(year == "TRUE")  %>% mutate(year = diff/(3600*24*365)) %>% arrange(desc(diff))

```

```{r,echo=FALSE,warning = FALSE,message=FALSE}

ggplot(data = m, mapping = aes(y = answer_score,x = min))+
  geom_point() + ggtitle("min") + ylim(0,1000) +
  ggtitle("Stackoverflow Threads: Timing of Response vs Answer Score") +
  xlab("Response Time (min)") +
  ylab("Answer Score")
ggplot(data = d, mapping = aes(y = answer_score,x = day))+
  geom_point() + ggtitle("day")+ ylim(0,1000) +
  ggtitle("Stackoverflow Threads: Timing of Response vs Answer Score") +
  xlab("Response Time (days)") +
  ylab("Answer Score")

```
```{r,echo=FALSE,include=FALSE}
ggplot(data = h, mapping = aes(y = answer_score,x = hour))+
  geom_point() + ggtitle("hour") + ylim(0,1000) 
ggplot(data = d, mapping = aes(y = answer_score,x = day))+
  geom_point() + ggtitle("day")+ ylim(0,1000) 
ggplot(data = w, mapping = aes(y = answer_score,x = week))+
  geom_point() + ggtitle("week") + ylim(0,1000) 
ggplot(data = y, mapping = aes(y = answer_score,x = year))+
  geom_point() + ggtitle("year")+ ylim(0,110) 
ggplot(data = s, mapping = aes(y = answer_score,x = diff))+
  geom_point() + ggtitle("sec")
```

* Findings/Explanation: We compared the time difference of questions and answers to the answer score. The graph shows that there was not a significant correlation between the two.  However, there appears to be a more slight negative correlation if we look at the time range of 0-60 minutes versus larger time ranges.  Therefore, we conclude that the timeliness of a response has little to no affect on the answer score. This could be because people might go through stackoverflow and choose which question they want to answer depending on the quality, not necessarily which one was posted first. 

```{r,echo=FALSE}
# stats try percentage of question answered within a minute, hour, day, week, year. and the amount of those
```

**** 
#### Arie's Section
****
* Question: How does the average score of answers compare to the average score of questions that have to do with python?

* Explanation: I wanted to see if questions and answers that specified that they were talking about python had an effect on the overall score of the question and answer.

```{r, echo=FALSE}
questionT<- merged3%>%
  select(question_title,answer_score, question_score, question_date, answer_body)%>%
  group_by(question_title, question_date, answer_body)%>%
  summarise(avg_Qscore = mean(question_score), avg_Ascore = mean(answer_score))

titlesPython <- questionT%>%
  filter(str_detect(question_title, "python"))

answerPython <- questionT%>%
  filter(str_detect(answer_body, "python"))


# compares avg question score and answer score of quesition titles that are about python
ggplot(data = titlesPython, mapping = aes(x = avg_Qscore, y = avg_Ascore ))+
  geom_point()+geom_smooth(method = lm)+
  ggtitle("Question titles about python : Average question score vs. Average answer score")+
  xlab("Average Answer Score")+
  ylab("Average Question Score")

correlation1 <-cor(titlesPython$avg_Qscore, titlesPython$avg_Ascore )
correlation1

# compares avg quesiton score and answer score of anser titles that are about python
ggplot(data = answerPython, mapping = aes(x = avg_Qscore, y = avg_Ascore ))+
  geom_point()+geom_smooth(method = lm)+
  ggtitle("Answers about python: Average question score vs. Average answer score")+
  xlab("Average Answer Score")+
  ylab("Average Question Score")

correlation2 <- cor(answerPython$avg_Qscore, answerPython$avg_Ascore)
correlation2

```
* Process: First I created a variable that looks at specfic columns in the data. I used `select()` to focus on the columns of data that I wanted to use. I then used `group_by()` to gather all reapted question titles and answer body. After that I use `summarize()` to get the average of answer score and question score. Then I created two new variables, one that searchs for the word "python" using `str_detect()` in the question titles. The other varible also searchs for the word python in the answer bodyusing `str_detect()`. Then I made a `ggplot()` for both variables using `geom_point()` with a best line of fit, to see if there were any differences between question titles and answer body regarding the scores. To see if there was a correletion between the average score for answers and question titles I used `cor()` function.

* Findings: I found that there was not much of a difference bewteen the plots. The overall count of question titles compared to answers was higher, but the graphs display a similar relationship between question score and answer score. When calculating the correlation for the graphs, they both displayed a strong positive correlation around 0.5(correlations are underneath each plot). From these graphs, it shows that there is a relation between a question score and answer score. For example, a poorly scored question relates to a low scored answer. This makes sense, because the quality of a question will determine how someone is going to respond to it.

* Explanation: My guess was that answer and question scores would be higher overall becuase they were more specific. Taking everthing into account, if the answer body or question title included "python" in it didn't seem to have an and affect on the score. But I did find a relationship bewteen question and answer scores.

**** 
#### David's Section
****

```{r, echo=FALSE}
gut <- merged3 %>% group_by(question_id) %>% mutate(ave = mean(answer_score)) %>% mutate(length = str_length(question_title)) %>% arrange(desc(ave)) 
 
get <- gut[,c(1,3,11,12)]  %>% unique()  
got <- get %>% filter(length < 5000, ave > 0, ave < 25) 
 
ggplot(data = get, mapping = aes(x = length, y = ave))+ 
  geom_point() + ylab("Average Anwser Score ") + xlab("Character Length of Question") + ggtitle("Score Vs. Length")
```

**** 
#### Ethan's Section
****

* Question: How does user question/answer politeness affect the score of their post?

* Explanation: I decided to pursue this question because I'm curious as to how people behave in response to polite words or lack thereof.

```{r, echo=FALSE}

polite <- merged3 %>%
  mutate(polite_question = ifelse(str_detect(question_body, "[T|t]hank you") | str_detect(question_body, "[T|t]hanks") |
         str_detect(question_body, "[P|p]lease") | str_detect(question_body, " [T|t]y "), "True", "False")) %>%
  mutate(polite_answer = ifelse(str_detect(answer_body, "[T|t]hank you") | str_detect(answer_body, "[T|t]hanks") |
         str_detect(answer_body, "[P|p]lease") | str_detect(answer_body, " [T|t]y "), "True", "False")) %>%
  group_by(polite_answer, polite_question, question_id) %>%
  summarise(avg_question_score = mean(question_score), avg_answer_score = mean(answer_score))

polite2 <- polite %>%
  group_by(polite_answer, polite_question) %>% #Another group_by required to deal with repeated question id's as a result of joining datasets
  summarise(avg_question_score = mean(avg_question_score), avg_answer_score = mean(avg_answer_score), count = n()) %>%
  unite(`polite_answer + polite_question`, polite_answer, polite_question, sep = " + ")

polite3 <- polite2[c(1,3,2,4)]

ggplot(data = polite3) +
  geom_point(mapping = aes(x = `polite_answer + polite_question`, y = avg_question_score, size = count), color = "blue") +
  geom_point(mapping = aes(x = `polite_answer + polite_question`, y = avg_answer_score, size = count), color = "green") +
  xlab("Polite Answer + Polite Question (True or False)") +
  ylab("Average Score") +
  ggtitle("Stackoverflow Threads: Politeness vs. Question/Answer Score", subtitle = "Blue = Question Score; Green = Answer Score")

```

* Process: I first created two new variables using ifelse(), having logical values of True or False depending upon my system's detection of common polite words.  I detected my answer bodies and question bodies for the words "please" and "thank you" and variations of these phrases to achieve this.  I then grouped by my two new variables and the question ID to get average question and answer scores for the 4 variations of "politeness."  Finally, I graphed the 4 variations of True/False against their repsective average question and answer scores, also taking their grouped counts into account using "size = count".

* Findings: My hypothesis was that polite questions and answers would receive higher average scores.  I was mostly proven wrong, especially when it came to average question scores as polite questions averaged scores of approxiately 12 (between False + True and True + True) and less polite questions averaged scores above 30! (between False + False and True + False). Also, when a polite question is "True", answer scores average barely over 6 whereas they average about 16 overwise.  It is notable that we have a much higher sample size for less polite questions, but these differences are still quite significant.  There doesn't appear to be as strong of a correlation between answer politeness and answer score itself, though the strength of an answer score consistently depends on the strength of the question score on average (Ex: A polite answer plus a less polite question yielded the highest average question score, as well as the highest average answer score).  

* Explanation: It is possible that more polite questions resulted in lower average question scores on StackOverflow because these types of questions reflect lack of knowledge on the subject as well as an undesirable informal approach to the complex subject of coding.  For example, people attempting to simply convince others to hand them code rather than show interest in more constructive help may feel more inclined to use words such as "please" or "thank you" in their questions.  Furthermore, average answer scores could correlate with average question scores because conversations may either go in a helpful direction or unhelpful direction on both ends.  Both the questioner and answerer can also both recieve the benefits of a popular thread, and both will also receieve the consequences of an unpopular thread.

**** 
#### Ryan's Section
****

##### string length of answer body vs answer score
```{r, echo=FALSE}


#get average score for each string length
boi <- merged3 %>% 
  group_by( str_length(answer_body)) %>%
  summarize(ave = mean(answer_score))

#got rid of some outliers messing up my graph >:(
boi1 <- boi %>%
  filter(ave < 750, `str_length(answer_body)` < 7500 )

#graph
ggplot(data = boi1, mapping = aes(x= `str_length(answer_body)`, y= ave)) +
  geom_point( alpha = 1/10) +
  geom_smooth( method='lm')


```


##### falsly postive word count in question body vs average score for question body   
```{r, echo=FALSE}



#make new column with count for the amount of "neat" words in each question body
merged4 <- merged3 %>%
  mutate(neat_count= str_count(question_body, c("neat", "neato","nice","noice")))

#get average score for each neat count
merged7 <-merged4 %>% 
  filter(neat_count < 3) %>% #neat count of 3 only happens once so it skews data
  group_by( neat_count) %>%
  summarize(ave = mean(question_score))

merged8 <-merged4 %>% 
  group_by( neat_count) %>%
  summarize(s = sum(question_score))

#graph
ggplot(data = merged7, mapping = aes(x = neat_count, y = ave)) +
  geom_point() +
  geom_smooth( method='lm')




```

* I created a feature called neat_count because I wanted to see the change in an questions score when they were positive, but maybe also slightly worried, which is displayed through the use of words like "neat", "neato","nice", and "noice".
* The relationship between question score and the count of worriedly positive words is slightly negative. This could be due to the fact that people who are worried about their post and try to remain positive are seen as being less honest than if they were just worried about getting an answer. The correlation isn't very strong though, and this could most likely be due to the fact that just becase someone used the word nice, it does not necessarily imply anything, whether about positivity or the level of worriedness.

* Also, I created a feature called str_length(answer_body) because I wanted to see the change in an answer's score when the answer became more extensive.
* The relationship between the length of the answer body and the score for the body is slightly positive, probably due to the fact that the more an answer is explained, the more likely the answer is right and thus will be upvoted. However, it is probably not more positive because some of the best answers are realtively simply and don't need a lot of words explaining them.

**** 
#### Anderson's Section
****

```{r, echo=FALSE}

```